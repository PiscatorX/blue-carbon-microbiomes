# blue-carbon-microbiomes
Analysis of blue carbon microbiomes 
# Getting started
## Creating a manifest file
Since the data has already been demultiplexed we will provide a [manifest file](https://docs.qiime2.org/2021.8/tutorials/importing/#fastq-manifest-formats) to import  the sequence reads. A manifest is similar to an experiment metadata file and can both be validated using the [Keemei](https://keemei.qiime2.org/) google sheets extension and error messages appear to refer to use "metadata" when referring to the manifest file when importing data.

Given the number of files, it is best to build the manifest using the script. I have created a [simple script](scripts/qiime_buildmanifest.py) for this purpose, this script is not extensively tested, so the output must be visually inspected. Download the script to your working directory and then provide it with the path to reads and the path where the manifest will be written to. We can then just run the script as follows:

```
python qiime_buildmanifest.py \
    -r /home/andhlovu/atacama_data/testdata \
    -m /home/andhlovu/metavars/atacama_manifest.tsv
```
## import reads into [QIIME](https://qiime2.org/)

Once we have a manifest file we can import our reads into QIIME

```
module load app/QIIME/2022.11

output_dir=/home/andhlovu/Atacama_soil
raw_reads=/home/andhlovu/atacama_data

qiime tools import \
   --type 'SampleData[PairedEndSequencesWithQuality]' \
   --input-path /home/andhlovu/metavars/atacama_manifest.tsv \
   --output-path ${output_dir}/raw_reads/emp-paired-end-sequences.qza \
   --input-format PairedEndFastqManifestPhred33V2

```
## Denoising and Sequence quality control with [DADA](https://benjjneb.github.io/dada2/)
We skip the de-multiplexing steps and jump to denoising in the Qiime workflow. Here we are using thresholds from the Atacama tutorial, these must be chosen following analysis of the quality of the data and therefore this step may have to be repeated until good quality data is produced. We also the ``` ``` option to take advantage of the cluster resources.

```
mkdir ${output_dir}/dada
qiime dada2 denoise-paired \
     --i-demultiplexed-seqs  ${output_dir}/raw_reads/emp-paired-end-sequences.qza \
     --p-trim-left-f 13 \
     --p-trim-left-r 13 \
     --p-trunc-len-f 150 \
     --p-trunc-len-r 150 \
     --p-n-threads ${threads} \
     --o-table ${output_dir}/dada/table.qza \
     --o-representative-sequences ${output_dir}/dada/rep-seqs.qza \
     --o-denoising-stats ${output_dir}/dada/denoising-stats.qza \
     --verbose

````
We can also visualise our results following the denoising. In Qiime visualisation have the ```*.qzv``` extension. To generate visualization of the dada table we run the following:

```
qiime metadata tabulate \
     --m-input-file ${output_dir}/dada/denoising-stats.qza \
     --o-visualization ${output_dir}/dada/denoising-stats.qzv
```

The DADA output ```rep-seqs.qza``` is the file of representative  sequences, these are generated by deduplicating the amplicon sequences. Using representative sequences, reduces the complexity of the data and resource requirements. The representative sequences represent OTUs at the 100% sequence identity and are generally referred to as amplicon sequence variants (ASV) and in some literature zero OTUs (zOTUs). It is now generally accepted that ASVs are better suited for amplicon data than OTUS at 97% identity, see the reference citation [here](https://www.nature.com/articles/ismej2017119). However,  OTUs remain in use particularly in the bar-coding research where they use long gene region sequences and there is empirical support for the 97% cut-off.

Now that we have our representative sequences, we will assign taxonomy to them, there numerous taxonomy assignment tools under Qiime; the Naive Bayes (NB) classifier has been shown to outperform other methods and is well suited for the taxonomy assignment task. The NB classifier must be trained on the gene region amplified, i.e targeted by the primers. To train the algorithm an in silico PCR using the forward and reverse primers is used on a reference database e.g SILVA. For more details on how to do this, see [here](https://docs.qiime2.org/2023.7/tutorials/feature-classifier/). However, for most commonly used primers sets, Qiime provides up-to-date BC classifiers, these can be found [here](https://docs.qiime2.org/2023.7/data-resources/). To classify our ASVs, we use the SILVA NB classifier trained on the region of our primer sets:515f/806r.

```
mkdir ${output_dir}/taxonomy
qiime feature-classifier classify-sklearn \
    --i-classifier /home/andhlovu/Qiime_DB_REF/silva-138-99-515-806-nb-classifier.qza \
    --i-reads ${output_dir}/dada/rep-seqs.qza \
    --p-n-jobs ${threads} \
    --o-classification ${output_dir}/taxonomy/taxonomy.qza \
    --verbose

qiime metadata tabulate \
    --m-input-file ${output_dir}/taxonomy/taxonomy.qza \
    --o-visualization ${output_dir}/taxonomy/taxonomy.qzv

mkdir ${output_dir}/phylogeny
qiime phylogeny align-to-tree-mafft-fasttree \
  --i-sequences ${output_dir}/dada/rep-seqs.qza \
  --p-n-threads ${threads} \
  --o-alignment ${output_dir}/phylogeny/aligned-rep-seqs.qza \
  --o-masked-alignment ${output_dir}/phylogeny/masked-aligned-rep-seqs.qza \
  --o-tree ${output_dir}/phylogeny/unrooted-tree.qza \
  --o-rooted-tree ${output_dir}/phylogeny/rooted-tree.qza

```


## Exporting qiime data to R
 
Data from qiime i.e. the *.qza artifacts can be imported directly into R, see for example, [qiime2R](https://github.com/jbisanz/qiime2R) Another option is to use ```qiime tools export``` to convert the artifacts into formats that can be used by other tools for downstream analysis e.g [phyloseq](https://joey711.github.io/phyloseq/) The ```for loop``` below can be used to export the four files that we need for any down
stream analysis outside of qiime:

| # | Filename | Description |
|---|----------|-------------|
| 1 | dna-sequences.fasta | Sequences of ASVs |
| 2 | feature-table.tsv |  ASVs read abundance for samples |
| 3 | taxonomy.tsv | ASV, taxonomy and confidence counts |
| 4 | tree.nwk | ASV rooted tree in newick format |		    

```
mkdir ${output_dir}/qiime2R
for qza in ${output_dir}/dada/table.qza \
${output_dir}/dada/rep-seqs.qza \
${output_dir}/taxonomy/taxonomy.qza \
${output_dir}/phylogeny/rooted-tree.qza 
do
 
    qiime tools export \
        --input-path ${qza}\
        --output-path ${output_dir}/qiime2R/ 
 
done

biom convert \
    --to-tsv \
    -i ${output_dir}/qiime2R/feature-table.biom \
    -o ${output_dir}/qiime2R/feature-table.tsv

```

## [phyloseq](https://www.bioconductor.org/packages/release/bioc/html/phyloseq.html) and [vegan]() analyis in R

To analyse our data we will make use of the [vegan](https://github.com/vegandevs/vegan) and [phyloseq](https://www.bioconductor.org/packages/release/bioc/html/phyloseq.html) packages, the links provide the installation instructions. We will then import the exported data into R. See the [jupyter notebook](qiime2R/qiime2R.ipynb) for examples of analysis under phyloseq and vegan.
